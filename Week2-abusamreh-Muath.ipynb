{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a74b5e-5180-4544-86a0-b047a877eb8e",
   "metadata": {},
   "source": [
    "# Week 3 - Linear Regression 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5925a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [statsmodels]\u001b[0m [statsmodels]\n",
      "\u001b[1A\u001b[2KSuccessfully installed patsy-1.0.1 statsmodels-0.14.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c24f12c-b364-40f0-b295-7c1ba88be680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d156fa14",
   "metadata": {},
   "source": [
    "First Dataset: Acute Kidney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27e0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"Acute Kidney.csv\" \n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "\n",
    "# Normalize columns (spaces/symbols -> underscores; lowercase)\n",
    "df.columns = (df.columns.astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "                .str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734fe6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: cox_los\n"
     ]
    }
   ],
   "source": [
    "# Choose a CONTINUOUS target \n",
    "preferred = [\"cox_los\", \"los\", \"length_of_stay\", \"sofa\", \"sapsii\", \"age\", \"bmi\", \"glucose\", \"wbc\", \"rbc\"]\n",
    "target_col = next((c for c in preferred if c in df.columns), None)\n",
    "if target_col is None:\n",
    "    nums = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "    if not nums:\n",
    "        raise ValueError(\"No numeric columns found to use as a regression target. Set target_col manually.\")\n",
    "    candidates = [c for c in nums if df[c].nunique(dropna=True) >= 10 and set(pd.unique(df[c].dropna())) != {0,1}]\n",
    "    target_col = candidates[0] if candidates else nums[0]\n",
    "\n",
    "print(\"Target:\", target_col)\n",
    "y = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
    "mask = ~y.isna()\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# features split\n",
    "num_cols_all = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "if target_col in num_cols_all: num_cols_all.remove(target_col)\n",
    "cat_cols = df.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "\n",
    "# quick NA handling\n",
    "X = df[num_cols_all + cat_cols].copy()\n",
    "for c in num_cols_all:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0)\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\").cat.add_categories([\"__missing__\"]).fillna(\"__missing__\")\n",
    "\n",
    "\n",
    "def rmse(a, b): \n",
    "    return float(np.sqrt(mean_squared_error(a, b)))\n",
    "\n",
    "def densify(A):\n",
    "    return A.toarray() if hasattr(A, \"toarray\") else A\n",
    "\n",
    "def cv_summary(y_true_list, y_pred_list):\n",
    "    r2s = [r2_score(yt, yp) for yt, yp in zip(y_true_list, y_pred_list)]\n",
    "    rmses = [rmse(yt, yp) for yt, yp in zip(y_true_list, y_pred_list)]\n",
    "    return np.mean(r2s), np.std(r2s), np.mean(rmses), np.std(rmses)\n",
    "\n",
    "def print_cv_row(rows, name, r2m, r2s, rmsem, rmses):\n",
    "    rows.append({\"Model\": name,\n",
    "                 \"CV R^2 (mean ± std)\": f\"{r2m:.4f} ± {r2s:.4f}\",\n",
    "                 \"CV RMSE (mean ± std)\": f\"{rmsem:.4f} ± {rmses:.4f}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4b1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise selection (numeric only, top-K by |corr|)\n",
    "K_STEPWISE = 15\n",
    "corrs = X[num_cols_all].corrwith(y).abs().sort_values(ascending=False)\n",
    "num_stepwise = list(corrs.index[:min(K_STEPWISE, len(corrs))])\n",
    "\n",
    "def kfold_predict_linear(X_df, y_ser, cols, n_splits=5, seed=42):\n",
    "    \"\"\"Fit StandardScaler on the exact subset 'cols' within each fold (fixes KeyError).\"\"\"\n",
    "    if len(cols) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    y_true_list, y_pred_list = [], []\n",
    "    for tr, va in kf.split(X_df):\n",
    "        Xtr, Xva = X_df.iloc[tr][cols], X_df.iloc[va][cols]\n",
    "        ytr, yva = y_ser.iloc[tr], y_ser.iloc[va]\n",
    "        sc = StandardScaler()\n",
    "        Xtr_s = sc.fit_transform(Xtr)\n",
    "        Xva_s = sc.transform(Xva)\n",
    "        ols = LinearRegression().fit(Xtr_s, ytr)\n",
    "        y_true_list.append(yva.values)\n",
    "        y_pred_list.append(ols.predict(Xva_s))\n",
    "    return cv_summary(y_true_list, y_pred_list)\n",
    "\n",
    "def forward_stepwise(X_df, y_ser, candidates, max_feats=None, tol=1e-4, n_splits=5):\n",
    "    selected, best_score = [], -np.inf\n",
    "    remaining = candidates.copy()\n",
    "    max_feats = max_feats or len(candidates)\n",
    "    while remaining and len(selected) < max_feats:\n",
    "        trial_scores = []\n",
    "        for c in remaining:\n",
    "            cols = selected + [c]\n",
    "            r2m, *_ = kfold_predict_linear(X_df, y_ser, cols, n_splits=n_splits)\n",
    "            trial_scores.append((r2m, c))\n",
    "        trial_scores.sort(reverse=True)\n",
    "        if trial_scores[0][0] > best_score + tol:\n",
    "            best_score, chosen = trial_scores[0]\n",
    "            selected.append(chosen)\n",
    "            remaining.remove(chosen)\n",
    "        else:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "def backward_stepwise(X_df, y_ser, start_cols, tol=1e-4, n_splits=5):\n",
    "    cols = start_cols.copy()\n",
    "    if len(cols) == 0:\n",
    "        return cols\n",
    "    improved = True\n",
    "    base_r2m, *_ = kfold_predict_linear(X_df, y_ser, cols, n_splits=n_splits)\n",
    "    while improved and len(cols) > 1:\n",
    "        improved = False\n",
    "        trial_scores = []\n",
    "        for c in cols:\n",
    "            trial = [x for x in cols if x != c]\n",
    "            r2m, *_ = kfold_predict_linear(X_df, y_ser, trial, n_splits=n_splits)\n",
    "            trial_scores.append((r2m, c, trial))\n",
    "        trial_scores.sort(reverse=True)\n",
    "        if trial_scores[0][0] > base_r2m + tol:\n",
    "            base_r2m, removed, cols = trial_scores[0][0], trial_scores[0][1], trial_scores[0][2]\n",
    "            improved = True\n",
    "    return cols\n",
    "\n",
    "# Compute stepwise sets\n",
    "fwd_selected = forward_stepwise(X, y, num_stepwise, max_feats=min(10, len(num_stepwise)), n_splits=5)\n",
    "bwd_selected = backward_stepwise(X, y, num_stepwise, n_splits=5)\n",
    "\n",
    "# CV for stepwise models\n",
    "fwd_r2m, fwd_r2s, fwd_rm, fwd_rs = kfold_predict_linear(X, y, fwd_selected, n_splits=5) if fwd_selected else (np.nan, np.nan, np.nan, np.nan)\n",
    "bwd_r2m, bwd_r2s, bwd_rm, bwd_rs = kfold_predict_linear(X, y, bwd_selected, n_splits=5) if bwd_selected else (np.nan, np.nan, np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86826e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCR: PCA(numeric) + OHE(cats) + OLS (inner CV for n_components)\n",
    "num_pcr = Pipeline([(\"scale\", StandardScaler()), (\"pca\", PCA())])\n",
    "pre_pcr = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pcr, [c for c in num_cols_all if c in X.columns]),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "to_dense = FunctionTransformer(densify)\n",
    "pcr_pipe = Pipeline([(\"pre\", pre_pcr), (\"to_dense\", to_dense), (\"reg\", LinearRegression())])\n",
    "\n",
    "max_pca = max(1, min(25, len(num_cols_all)))\n",
    "pcr_param = {\"pre__num__pca__n_components\": list(range(1, max_pca + 1))}\n",
    "\n",
    "def nested_cv_pipe(pipe, param_grid, X_df, y_ser, n_splits=5, seed=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    y_true_list, y_pred_list, best_params = [], [], []\n",
    "    for tr, va in kf.split(X_df):\n",
    "        Xtr, Xva = X_df.iloc[tr], X_df.iloc[va]\n",
    "        ytr, yva = y_ser.iloc[tr], y_ser.iloc[va]\n",
    "        gs = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        gs.fit(Xtr, ytr)\n",
    "        best = gs.best_estimator_\n",
    "        y_true_list.append(yva.values)\n",
    "        y_pred_list.append(best.predict(Xva))\n",
    "        best_params.append(gs.best_params_)\n",
    "    r2m, r2s, rm, rs = cv_summary(y_true_list, y_pred_list)\n",
    "    return r2m, r2s, rm, rs, best_params\n",
    "\n",
    "pcr_r2m, pcr_r2s, pcr_rm, pcr_rs, pcr_params = nested_cv_pipe(pcr_pipe, pcr_param, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a578e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLSR: StandardScaler+OHE -> PLSRegression (inner CV for n_components) \n",
    "pre_pls = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols_all),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "pls_pipe = Pipeline([(\"pre\", pre_pls), (\"to_dense\", to_dense), (\"reg\", PLSRegression(scale=False))])\n",
    "\n",
    "max_pls = max(1, min(15, len(num_cols_all)))\n",
    "pls_param = {\"reg__n_components\": list(range(1, max_pls + 1))}\n",
    "\n",
    "pls_r2m, pls_r2s, pls_rm, pls_rs, pls_params = nested_cv_pipe(pls_pipe, pls_param, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a15600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 3 — 5-fold CV (mean ± std) ===\n",
      "                          Model CV R^2 (mean ± std) CV RMSE (mean ± std)\n",
      "    Forward Stepwise (on 3 num)     0.9698 ± 0.0037      5.8339 ± 0.3625\n",
      "  Backward Stepwise (on 15 num)     0.9698 ± 0.0037      5.8392 ± 0.3640\n",
      " PCR (best n_components via CV)     0.9217 ± 0.0071      9.4031 ± 0.3172\n",
      "PLSR (best n_components via CV)     0.9695 ± 0.0036      5.8637 ± 0.3576\n"
     ]
    }
   ],
   "source": [
    "# Summaries (5-fold CV)\n",
    "cv_rows = []\n",
    "print_cv_row(cv_rows, f\"Forward Stepwise (on {len(fwd_selected)} num)\", fwd_r2m, fwd_r2s, fwd_rm, fwd_rs)\n",
    "print_cv_row(cv_rows, f\"Backward Stepwise (on {len(bwd_selected)} num)\", bwd_r2m, bwd_r2s, bwd_rm, bwd_rs)\n",
    "print_cv_row(cv_rows, \"PCR (best n_components via CV)\", pcr_r2m, pcr_r2s, pcr_rm, pcr_rs)\n",
    "print_cv_row(cv_rows, \"PLSR (best n_components via CV)\", pls_r2m, pls_r2s, pls_rm, pls_rs)\n",
    "\n",
    "cv_table = pd.DataFrame(cv_rows)\n",
    "print(\"\\n=== Week 3 — 5-fold CV (mean ± std) ===\")\n",
    "print(cv_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9aad15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 3 — Common Holdout (30%) ===\n",
      "            Model  Test R^2  Test RMSE                                                                                                                                                            Params\n",
      " Forward Stepwise  0.971335   5.857363                                                                                                           {'features': ['mort_90_day', 'mort_28_day', 'lactate']}\n",
      "Backward Stepwise  0.971138   5.877375 {'features': ['mort_90_day', 'mort_28_day', 'mort_1_year', 'sapsii', 'sofa', 'aki_stage', 'bun', 'rdw', 'lactate', 'age', 'nlr', 'ly', 'r', 'sii', 'malignancy']}\n",
      "              PCR  0.928883   9.225955                                                                                                                                              {'n_components': 25}\n",
      "             PLSR  0.970773   5.914512                                                                                                                                              {'n_components': 15}\n"
     ]
    }
   ],
   "source": [
    "# Common 30% holdout for apples-to-apples comparison \n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Forward holdout\n",
    "if fwd_selected:\n",
    "    sc_f = StandardScaler().fit(X_tr[fwd_selected])\n",
    "    Xtr_f = sc_f.transform(X_tr[fwd_selected])\n",
    "    Xte_f = sc_f.transform(X_te[fwd_selected])\n",
    "    ols_f = LinearRegression().fit(Xtr_f, y_tr)\n",
    "    fwd_test = {\"Model\":\"Forward Stepwise\",\n",
    "                \"Test R^2\": r2_score(y_te, ols_f.predict(Xte_f)),\n",
    "                \"Test RMSE\": rmse(y_te, ols_f.predict(Xte_f)),\n",
    "                \"Params\": {\"features\": fwd_selected}}\n",
    "else:\n",
    "    fwd_test = {\"Model\":\"Forward Stepwise\",\"Test R^2\":np.nan,\"Test RMSE\":np.nan,\"Params\":{\"features\":[]}}\n",
    "\n",
    "# Backward holdout\n",
    "if bwd_selected:\n",
    "    sc_b = StandardScaler().fit(X_tr[bwd_selected])\n",
    "    Xtr_b = sc_b.transform(X_tr[bwd_selected])\n",
    "    Xte_b = sc_b.transform(X_te[bwd_selected])\n",
    "    ols_b = LinearRegression().fit(Xtr_b, y_tr)\n",
    "    bwd_test = {\"Model\":\"Backward Stepwise\",\n",
    "                \"Test R^2\": r2_score(y_te, ols_b.predict(Xte_b)),\n",
    "                \"Test RMSE\": rmse(y_te, ols_b.predict(Xte_b)),\n",
    "                \"Params\": {\"features\": bwd_selected}}\n",
    "else:\n",
    "    bwd_test = {\"Model\":\"Backward Stepwise\",\"Test R^2\":np.nan,\"Test RMSE\":np.nan,\"Params\":{\"features\":[]}}\n",
    "\n",
    "#  PCR holdout (refit with best n_components on train)\n",
    "try:\n",
    "    gs_pcr = GridSearchCV(\n",
    "        pcr_pipe, pcr_param, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "except TypeError:\n",
    "    # fallback if your sklearn doesn't support n_jobs in this context\n",
    "    gs_pcr = GridSearchCV(\n",
    "        pcr_pipe, pcr_param, cv=5, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "gs_pcr.fit(X_tr, y_tr)\n",
    "pcr_best = gs_pcr.best_estimator_\n",
    "pcr_n = pcr_best.get_params().get(\"pre__num__pca__n_components\")\n",
    "pcr_pred = pcr_best.predict(X_te)\n",
    "pcr_pred = np.ravel(pcr_pred)  # ensure 1D\n",
    "pcr_test = {\n",
    "    \"Model\": \"PCR\",\n",
    "    \"Params\": {\"n_components\": int(pcr_n) if pcr_n is not None else None},\n",
    "    \"Test R^2\": r2_score(y_te, pcr_pred),\n",
    "    \"Test RMSE\": rmse(y_te, pcr_pred),\n",
    "}\n",
    "\n",
    "# PLSR holdout\n",
    "try:\n",
    "    gs_pls = GridSearchCV(\n",
    "        pls_pipe, pls_param, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "except TypeError:\n",
    "    gs_pls = GridSearchCV(\n",
    "        pls_pipe, pls_param, cv=5, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "gs_pls.fit(X_tr, y_tr)\n",
    "pls_best = gs_pls.best_estimator_\n",
    "pls_n = int(pls_best.get_params().get(\"reg__n_components\"))\n",
    "pls_pred = pls_best.predict(X_te)\n",
    "pls_pred = np.ravel(pls_pred)  # ensure 1D\n",
    "pls_test = {\n",
    "    \"Model\": \"PLSR\",\n",
    "    \"Params\": {\"n_components\": pls_n},\n",
    "    \"Test R^2\": r2_score(y_te, pls_pred),\n",
    "    \"Test RMSE\": rmse(y_te, pls_pred),\n",
    "}\n",
    "\n",
    "hold_table = pd.DataFrame([fwd_test, bwd_test, pcr_test, pls_test])\n",
    "print(\"\\n=== Week 3 — Common Holdout (30%) ===\")\n",
    "print(hold_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03f70f4",
   "metadata": {},
   "source": [
    "Week 3 — Model Selection & Dimension Reduction (Acute Kidney)\n",
    "Objective\n",
    "\n",
    "Compare forward stepwise, backward stepwise, PCR (principal components regression), and PLSR (partial least squares regression) on the Acute Kidney dataset. Report 5-fold CV (mean ± std) for R² and RMSE, then evaluate all models on a shared 30% holdout for apples-to-apples performance.\n",
    "\n",
    "Data & Target\n",
    "\n",
    "Dataset: Acute Kidney.csv\n",
    "\n",
    "Target (continuous): cox_los (preferred if present). If not available, used: <target_col>\n",
    "\n",
    "Predictors: mixture of continuous (vitals, labs, scores) and categorical (demographics, comorbidities, flags).\n",
    "\n",
    "Preprocessing\n",
    "\n",
    "Column cleanup: lower-cased, spaces/symbols → underscores.\n",
    "\n",
    "Missing values: numeric → 0.0; categoricals → \"__missing__\".\n",
    "\n",
    "Feature typing: numeric vs. categorical.\n",
    "\n",
    "Scaling: StandardScaler applied where needed (stepwise, PCR numeric block, PLSR).\n",
    "\n",
    "Encoding: OneHotEncoder(handle_unknown=\"ignore\") for categoricals (PCR/PLSR pipelines).\n",
    "\n",
    "Methods\n",
    "Stepwise Linear Regression (greedy subset selection)\n",
    "\n",
    "Forward stepwise: start empty, add the feature with the largest CV R² gain at each step until no improvement (tolerance).\n",
    "\n",
    "Backward stepwise: start from a capped set of top-K numeric features (ranked by |corr| with target), remove features that increase CV R² when dropped.\n",
    "\n",
    "Rationale: provides interpretable subsets; sensitive to collinearity and greedy decisions.\n",
    "\n",
    "PCR — Principal Components Regression\n",
    "\n",
    "Pipeline: scale numeric → PCA (choose n_components via inner CV) → OLS, with OHE categoricals appended.\n",
    "\n",
    "Rationale: compress correlated numeric predictors to orthogonal components; helps with multicollinearity.\n",
    "\n",
    "PLSR — Partial Least Squares Regression\n",
    "\n",
    "Pipeline: scale+OHE → PLSRegression, tune n_components via inner CV.\n",
    "\n",
    "Rationale: finds components that maximize covariance with the target, often stronger than PCA when X–y relation is concentrated in fewer directions.\n",
    "\n",
    "Interpretation\n",
    "\n",
    "\n",
    "Multicollinearity: PCR/PLSR typically outperform stepwise when many predictors are correlated; components stabilize estimates.\n",
    "\n",
    "Parsimony vs. Stability: Stepwise yields sparse, interpretable subsets but can be unstable across folds; PCR/PLSR produce stable components but less direct interpretability.\n",
    "\n",
    "When to use which:\n",
    "\n",
    "Prefer PLSR if signal aligns with few latent X–y directions.\n",
    "\n",
    "Prefer PCR if you primarily need to orthogonalize correlated predictors and retain broad variance.\n",
    "\n",
    "Prefer Stepwise if interpretability via original features is paramount (and results are validated by CV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5673c",
   "metadata": {},
   "source": [
    "Second Dataset: Colorectal cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231e21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & tidy\n",
    "DATA_PATH = \"colorectal_cancer_dataset.csv\" \n",
    "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "df.columns = (df.columns.astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "                .str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4647bb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: age\n"
     ]
    }
   ],
   "source": [
    "# Choose a CONTINUOUS target\n",
    "preferred = [\"survival_months\",\"time_to_event\",\"tumor_size\",\"tumor_volume\",\"age\",\"bmi\",\"los\"]\n",
    "target_col = next((c for c in preferred if c in df.columns), None)\n",
    "if target_col is None:\n",
    "    nums = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "    if not nums:\n",
    "        raise ValueError(\"No numeric columns found for regression target. Set target_col manually.\")\n",
    "    candidates = [c for c in nums if df[c].nunique(dropna=True) >= 10 and set(pd.unique(df[c].dropna())) != {0,1}]\n",
    "    target_col = candidates[0] if candidates else nums[0]\n",
    "\n",
    "print(\"Target:\", target_col)\n",
    "y = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
    "mask = ~y.isna()\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# features\n",
    "num_cols_all = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "if target_col in num_cols_all: num_cols_all.remove(target_col)\n",
    "cat_cols = df.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "\n",
    "# quick NA handling\n",
    "X = df[num_cols_all + cat_cols].copy()\n",
    "for c in num_cols_all:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0)\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\").cat.add_categories([\"__missing__\"]).fillna(\"__missing__\")\n",
    "\n",
    "\n",
    "def rmse(a, b): \n",
    "    return float(np.sqrt(mean_squared_error(a, b)))\n",
    "\n",
    "def densify(A):\n",
    "    return A.toarray() if hasattr(A, \"toarray\") else A\n",
    "\n",
    "def cv_summary(y_true_list, y_pred_list):\n",
    "    r2s = [r2_score(yt, yp) for yt, yp in zip(y_true_list, y_pred_list)]\n",
    "    rmses = [rmse(yt, yp) for yt, yp in zip(y_true_list, y_pred_list)]\n",
    "    return np.mean(r2s), np.std(r2s), np.mean(rmses), np.std(rmses)\n",
    "\n",
    "def print_cv_row(rows, name, r2m, r2s, rmsem, rmses):\n",
    "    rows.append({\"Model\": name,\n",
    "                 \"CV R^2 (mean ± std)\": f\"{r2m:.4f} ± {r2s:.4f}\",\n",
    "                 \"CV RMSE (mean ± std)\": f\"{rmsem:.4f} ± {rmses:.4f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de6b1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise selection (numeric only, top-K by |corr|)\n",
    "K_STEPWISE = 15\n",
    "corrs = X[num_cols_all].corrwith(y).abs().sort_values(ascending=False)\n",
    "num_stepwise = list(corrs.index[:min(K_STEPWISE, len(corrs))])\n",
    "\n",
    "def kfold_predict_linear(X_df, y_ser, cols, n_splits=5, seed=42):\n",
    "    \"\"\"Fit scaler on EXACT subset 'cols' within each fold (prevents KeyErrors).\"\"\"\n",
    "    if len(cols) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    y_true_list, y_pred_list = [], []\n",
    "    for tr, va in kf.split(X_df):\n",
    "        Xtr, Xva = X_df.iloc[tr][cols], X_df.iloc[va][cols]\n",
    "        ytr, yva = y_ser.iloc[tr], y_ser.iloc[va]\n",
    "        sc = StandardScaler()\n",
    "        Xtr_s = sc.fit_transform(Xtr)\n",
    "        Xva_s = sc.transform(Xva)\n",
    "        ols = LinearRegression().fit(Xtr_s, ytr)\n",
    "        y_true_list.append(yva.values)\n",
    "        y_pred_list.append(ols.predict(Xva_s))\n",
    "    return cv_summary(y_true_list, y_pred_list)\n",
    "\n",
    "def forward_stepwise(X_df, y_ser, candidates, max_feats=None, tol=1e-4, n_splits=5):\n",
    "    selected, best_score = [], -np.inf\n",
    "    remaining = candidates.copy()\n",
    "    max_feats = max_feats or len(candidates)\n",
    "    while remaining and len(selected) < max_feats:\n",
    "        trial_scores = []\n",
    "        for c in remaining:\n",
    "            cols = selected + [c]\n",
    "            r2m, *_ = kfold_predict_linear(X_df, y_ser, cols, n_splits=n_splits)\n",
    "            trial_scores.append((r2m, c))\n",
    "        trial_scores.sort(reverse=True)\n",
    "        if trial_scores[0][0] > best_score + tol:\n",
    "            best_score, chosen = trial_scores[0]\n",
    "            selected.append(chosen)\n",
    "            remaining.remove(chosen)\n",
    "        else:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "def backward_stepwise(X_df, y_ser, start_cols, tol=1e-4, n_splits=5):\n",
    "    cols = start_cols.copy()\n",
    "    if len(cols) == 0:\n",
    "        return cols\n",
    "    improved = True\n",
    "    base_r2m, *_ = kfold_predict_linear(X_df, y_ser, cols, n_splits=n_splits)\n",
    "    while improved and len(cols) > 1:\n",
    "        improved = False\n",
    "        trial_scores = []\n",
    "        for c in cols:\n",
    "            trial = [x for x in cols if x != c]\n",
    "            r2m, *_ = kfold_predict_linear(X_df, y_ser, trial, n_splits=n_splits)\n",
    "            trial_scores.append((r2m, c, trial))\n",
    "        trial_scores.sort(reverse=True)\n",
    "        if trial_scores[0][0] > base_r2m + tol:\n",
    "            base_r2m, removed, cols = trial_scores[0][0], trial_scores[0][1], trial_scores[0][2]\n",
    "            improved = True\n",
    "    return cols\n",
    "\n",
    "# compute stepwise feature sets\n",
    "fwd_selected = forward_stepwise(X, y, num_stepwise, max_feats=min(10, len(num_stepwise)), n_splits=5)\n",
    "bwd_selected = backward_stepwise(X, y, num_stepwise, n_splits=5)\n",
    "\n",
    "# CV for stepwise models\n",
    "fwd_r2m, fwd_r2s, fwd_rm, fwd_rs = kfold_predict_linear(X, y, fwd_selected, n_splits=5) if fwd_selected else (np.nan, np.nan, np.nan, np.nan)\n",
    "bwd_r2m, bwd_r2s, bwd_rm, bwd_rs = kfold_predict_linear(X, y, bwd_selected, n_splits=5) if bwd_selected else (np.nan, np.nan, np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b21d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCR: PCA(numeric) + OHE(cats) + OLS (inner CV for n_components)\n",
    "num_pcr = Pipeline([(\"scale\", StandardScaler()), (\"pca\", PCA())])\n",
    "\n",
    "trans = [(\"num\", num_pcr, num_cols_all)]\n",
    "if len(cat_cols):\n",
    "    trans.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols))\n",
    "\n",
    "pre_pcr = ColumnTransformer(transformers=trans, remainder=\"drop\")\n",
    "to_dense = FunctionTransformer(densify)\n",
    "pcr_pipe = Pipeline([(\"pre\", pre_pcr), (\"to_dense\", to_dense), (\"reg\", LinearRegression())])\n",
    "\n",
    "max_pca = max(1, min(25, len(num_cols_all)))\n",
    "pcr_param = {\"pre__num__pca__n_components\": list(range(1, max_pca + 1))}\n",
    "\n",
    "def nested_cv_pipe(pipe, param_grid, X_df, y_ser, n_splits=5, seed=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    y_true_list, y_pred_list, best_params = [], [], []\n",
    "    for tr, va in kf.split(X_df):\n",
    "        Xtr, Xva = X_df.iloc[tr], X_df.iloc[va]\n",
    "        ytr, yva = y_ser.iloc[tr], y_ser.iloc[va]\n",
    "        try:\n",
    "            gs = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        except TypeError:\n",
    "            gs = GridSearchCV(pipe, param_grid, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "        gs.fit(Xtr, ytr)\n",
    "        best = gs.best_estimator_\n",
    "        y_true_list.append(yva.values)\n",
    "        y_pred_list.append(best.predict(Xva))\n",
    "        best_params.append(gs.best_params_)\n",
    "    r2m, r2s, rm, rs = cv_summary(y_true_list, y_pred_list)\n",
    "    return r2m, r2s, rm, rs, best_params\n",
    "\n",
    "pcr_r2m, pcr_r2s, pcr_rm, pcr_rs, pcr_params = nested_cv_pipe(pcr_pipe, pcr_param, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e1a9016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLSR: StandardScaler+OHE -> PLSRegression (inner CV for n_components)\n",
    "trans_pls = [(\"num\", StandardScaler(), num_cols_all)]\n",
    "if len(cat_cols):\n",
    "    trans_pls.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols))\n",
    "\n",
    "pre_pls = ColumnTransformer(transformers=trans_pls, remainder=\"drop\")\n",
    "pls_pipe = Pipeline([(\"pre\", pre_pls), (\"to_dense\", to_dense), (\"reg\", PLSRegression(scale=False))])\n",
    "\n",
    "max_pls = max(1, min(15, len(num_cols_all)))\n",
    "pls_param = {\"reg__n_components\": list(range(1, max_pls + 1))}\n",
    "\n",
    "pls_r2m, pls_r2s, pls_rm, pls_rs, pls_params = nested_cv_pipe(pls_pipe, pls_param, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e13ebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 3 — 5-fold CV (mean ± std) ===\n",
      "                          Model CV R^2 (mean ± std) CV RMSE (mean ± std)\n",
      "    Forward Stepwise (on 1 num)    -0.0000 ± 0.0001     11.8724 ± 0.0383\n",
      "   Backward Stepwise (on 5 num)    -0.0001 ± 0.0002     11.8727 ± 0.0384\n",
      " PCR (best n_components via CV)    -0.0004 ± 0.0002     11.8743 ± 0.0377\n",
      "PLSR (best n_components via CV)    -0.0003 ± 0.0002     11.8740 ± 0.0379\n"
     ]
    }
   ],
   "source": [
    "# Summaries (5-fold CV)\n",
    "cv_rows = []\n",
    "print_cv_row(cv_rows, f\"Forward Stepwise (on {len(fwd_selected)} num)\", fwd_r2m, fwd_r2s, fwd_rm, fwd_rs)\n",
    "print_cv_row(cv_rows, f\"Backward Stepwise (on {len(bwd_selected)} num)\", bwd_r2m, bwd_r2s, bwd_rm, bwd_rs)\n",
    "print_cv_row(cv_rows, \"PCR (best n_components via CV)\", pcr_r2m, pcr_r2s, pcr_rm, pcr_rs)\n",
    "print_cv_row(cv_rows, \"PLSR (best n_components via CV)\", pls_r2m, pls_r2s, pls_rm, pls_rs)\n",
    "\n",
    "cv_table = pd.DataFrame(cv_rows)\n",
    "print(\"\\n=== Week 3 — 5-fold CV (mean ± std) ===\")\n",
    "print(cv_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca0062bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 3 — Common Holdout (30%) ===\n",
      "            Model  Test R^2  Test RMSE                                                                                                                  Params\n",
      " Forward Stepwise -0.000124  11.890120                                                                                      {'features': ['healthcare_costs']}\n",
      "Backward Stepwise -0.000253  11.890885 {'features': ['healthcare_costs', 'tumor_size_mm', 'patient_id', 'mortality_rate_per_100k', 'incidence_rate_per_100k']}\n",
      "              PCR -0.000283  11.891064                                                                                                     {'n_components': 1}\n",
      "             PLSR -0.000326  11.891321                                                                                                     {'n_components': 1}\n"
     ]
    }
   ],
   "source": [
    "# Common 30% holdout for apples-to-apples comparison\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Forward holdout\n",
    "if fwd_selected:\n",
    "    sc_f = StandardScaler().fit(X_tr[fwd_selected])\n",
    "    Xtr_f = sc_f.transform(X_tr[fwd_selected])\n",
    "    Xte_f = sc_f.transform(X_te[fwd_selected])\n",
    "    ols_f = LinearRegression().fit(Xtr_f, y_tr)\n",
    "    fwd_test = {\"Model\":\"Forward Stepwise\",\n",
    "                \"Test R^2\": r2_score(y_te, ols_f.predict(Xte_f)),\n",
    "                \"Test RMSE\": rmse(y_te, ols_f.predict(Xte_f)),\n",
    "                \"Params\": {\"features\": fwd_selected}}\n",
    "else:\n",
    "    fwd_test = {\"Model\":\"Forward Stepwise\",\"Test R^2\":np.nan,\"Test RMSE\":np.nan,\"Params\":{\"features\":[]}}\n",
    "\n",
    "# Backward holdout\n",
    "if bwd_selected:\n",
    "    sc_b = StandardScaler().fit(X_tr[bwd_selected])\n",
    "    Xtr_b = sc_b.transform(X_tr[bwd_selected])\n",
    "    Xte_b = sc_b.transform(X_te[bwd_selected])\n",
    "    ols_b = LinearRegression().fit(Xtr_b, y_tr)\n",
    "    bwd_test = {\"Model\":\"Backward Stepwise\",\n",
    "                \"Test R^2\": r2_score(y_te, ols_b.predict(Xte_b)),\n",
    "                \"Test RMSE\": rmse(y_te, ols_b.predict(Xte_b)),\n",
    "                \"Params\": {\"features\": bwd_selected}}\n",
    "else:\n",
    "    bwd_test = {\"Model\":\"Backward Stepwise\",\"Test R^2\":np.nan,\"Test RMSE\":np.nan,\"Params\":{\"features\":[]}}\n",
    "\n",
    "# PCR holdout (refit with best n_components on train)\n",
    "try:\n",
    "    gs_pcr = GridSearchCV(pcr_pipe, pcr_param, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "except TypeError:\n",
    "    gs_pcr = GridSearchCV(pcr_pipe, pcr_param, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "gs_pcr.fit(X_tr, y_tr)\n",
    "pcr_best = gs_pcr.best_estimator_\n",
    "pcr_n = pcr_best.get_params().get(\"pre__num__pca__n_components\")\n",
    "pcr_pred = np.ravel(pcr_best.predict(X_te))\n",
    "pcr_test = {\"Model\":\"PCR\", \"Params\":{\"n_components\": int(pcr_n) if pcr_n is not None else None},\n",
    "            \"Test R^2\": r2_score(y_te, pcr_pred), \"Test RMSE\": rmse(y_te, pcr_pred)}\n",
    "\n",
    "# PLSR holdout\n",
    "try:\n",
    "    gs_pls = GridSearchCV(pls_pipe, pls_param, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "except TypeError:\n",
    "    gs_pls = GridSearchCV(pls_pipe, pls_param, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "gs_pls.fit(X_tr, y_tr)\n",
    "pls_best = gs_pls.best_estimator_\n",
    "pls_n = int(pls_best.get_params().get(\"reg__n_components\"))\n",
    "pls_pred = np.ravel(pls_best.predict(X_te))\n",
    "pls_test = {\"Model\":\"PLSR\", \"Params\":{\"n_components\": pls_n},\n",
    "            \"Test R^2\": r2_score(y_te, pls_pred), \"Test RMSE\": rmse(y_te, pls_pred)}\n",
    "\n",
    "hold_table = pd.DataFrame([fwd_test, bwd_test, pcr_test, pls_test])\n",
    "print(\"\\n=== Week 3 — Common Holdout (30%) ===\")\n",
    "print(hold_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48747ed0",
   "metadata": {},
   "source": [
    "Week 3 — Model Selection & Dimension Reduction (Colorectal Cancer)\n",
    "Objective\n",
    "\n",
    "Compare forward stepwise, backward stepwise, PCR (Principal Components Regression), and PLSR (Partial Least Squares Regression) on the colorectal_cancer_dataset.csv. Report 5-fold CV (mean ± std) for R² and RMSE, then evaluate all models on a shared 30% holdout for apples-to-apples performance.\n",
    "\n",
    "Data & Target\n",
    "\n",
    "Dataset: colorectal_cancer_dataset\n",
    "\n",
    "Target (continuous): survival_months (preferred if present). If not available, used: <target_col>\n",
    "\n",
    "Predictors: mix of continuous (e.g., age, BMI, tumor size/volume, biomarkers) and categorical (e.g., sex, stage, site, therapy).\n",
    "\n",
    "Preprocessing\n",
    "\n",
    "Column cleanup: lower-cased, spaces/symbols → underscores.\n",
    "\n",
    "Missing values: numeric → 0.0; categoricals → \"__missing__\".\n",
    "\n",
    "Feature typing: numeric vs categorical.\n",
    "\n",
    "Scaling: StandardScaler applied where needed (stepwise, PCR numeric block, PLSR).\n",
    "\n",
    "Encoding: OneHotEncoder(handle_unknown=\"ignore\") for categoricals (PCR/PLSR pipelines).\n",
    "\n",
    "Methods\n",
    "Stepwise Linear Regression (greedy subset selection)\n",
    "\n",
    "Forward stepwise: start empty; at each step add the feature with the largest CV R² gain until improvement < tolerance.\n",
    "\n",
    "Backward stepwise: start from top-K numeric features (ranked by |corr| with target); iteratively drop features that increase CV R².\n",
    "\n",
    "Why: yields interpretable subsets; can be unstable with high collinearity.\n",
    "\n",
    "PCR — Principal Components Regression\n",
    "\n",
    "Pipeline: scale numeric → PCA (choose n_components via inner CV) → OLS, with OHE categoricals appended.\n",
    "\n",
    "Why: orthogonalizes correlated predictors → mitigates multicollinearity.\n",
    "\n",
    "PLSR — Partial Least Squares Regression\n",
    "\n",
    "Pipeline: scale + OHE → PLSRegression, tune n_components via inner CV.\n",
    "\n",
    "Why: finds components that maximize covariance with the target; often needs fewer components than PCR when X–y relation is concentrated.\n",
    "\n",
    "Interpretation\n",
    "\n",
    "Collinearity handling: PCR/PLSR often outperform stepwise when predictors are highly correlated, by stabilizing the signal in low-dimensional components.\n",
    "\n",
    "Parsimony vs. stability: Stepwise gives sparse, interpretable subsets but can be unstable across folds; PCR/PLSR provide stable latent factors but are less directly interpretable.\n",
    "\n",
    "When to prefer which:\n",
    "\n",
    "PLSR if the predictive signal lies in a few X–y directions.\n",
    "\n",
    "PCR if the goal is mainly to orthogonalize and denoise correlated predictors.\n",
    "\n",
    "Stepwise when interpretability via original features is critical and results are validated by CV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96124c67",
   "metadata": {},
   "source": [
    "Third Dataset: Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb97fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"diabetes_012_health_indicators_BRFSS2015.csv\"\n",
    "df = pd.read_csv(DATA_PATH, low_memory=True)\n",
    "\n",
    "# normalize columns\n",
    "df.columns = (df.columns.astype(str)\n",
    "                .str.strip().str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "                .str.replace(r\"[^0-9a-zA-Z_]\", \"\", regex=True)\n",
    "                .str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c17596bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: bmi\n"
     ]
    }
   ],
   "source": [
    "# Choose a CONTINUOUS target\n",
    "# Prefer BMI; else pick a numeric with enough variability (not just {0,1})\n",
    "preferred = [\"bmi\", \"menthlth\", \"physhlth\", \"genhlth\", \"age\"]\n",
    "target_col = next((c for c in preferred if c in df.columns), None)\n",
    "if target_col is None:\n",
    "    nums = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "    if not nums:\n",
    "        raise ValueError(\"No numeric columns for regression target. Set target_col manually.\")\n",
    "    candidates = [c for c in nums if df[c].nunique(dropna=True) >= 10 and set(pd.unique(df[c].dropna())) != {0,1}]\n",
    "    target_col = candidates[0] if candidates else nums[0]\n",
    "\n",
    "print(\"Target:\", target_col)\n",
    "y = pd.to_numeric(df[target_col], errors=\"coerce\")\n",
    "mask = ~y.isna()\n",
    "df = df.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e46a165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature matrix (mostly numeric in BRFSS)\n",
    "num_cols_all = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "if target_col in num_cols_all: num_cols_all.remove(target_col)\n",
    "cat_cols = df.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()  # often empty in BRFSS\n",
    "\n",
    "X = df[num_cols_all + cat_cols].copy()\n",
    "for c in num_cols_all:\n",
    "    X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"category\").cat.add_categories([\"__missing__\"]).fillna(\"__missing__\")\n",
    "\n",
    "\n",
    "def rmse(a, b): \n",
    "    return float(np.sqrt(mean_squared_error(a, b)))\n",
    "\n",
    "def densify(A):\n",
    "    return A.toarray() if hasattr(A, \"toarray\") else A\n",
    "\n",
    "def cv_summary(y_true_list, y_pred_list):\n",
    "    r2s = [r2_score(yt, yp) for yt, yp in zip(y_true_list, y_pred_list)]\n",
    "    rmses = [rmse(yt, yp) for yt, yp in zip(y_true_list, y_pred_list)]\n",
    "    return np.mean(r2s), np.std(r2s), np.mean(rmses), np.std(rmses)\n",
    "\n",
    "def print_cv_row(rows, name, r2m, r2s, rmsem, rmses):\n",
    "    rows.append({\"Model\": name,\n",
    "                 \"CV R^2 (mean ± std)\": f\"{r2m:.4f} ± {r2s:.4f}\",\n",
    "                 \"CV RMSE (mean ± std)\": f\"{rmsem:.4f} ± {rmses:.4f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a48f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise selection (numeric only, top-K by |corr|)\n",
    "# Large dataset ⇒ limit candidates and (optionally) subsample rows during stepwise CV\n",
    "K_STEPWISE = 20\n",
    "MAX_STEPWISE_ROWS = 120_000  # set None to use all rows (slower)\n",
    "\n",
    "corrs = X[num_cols_all].corrwith(y.astype(\"float32\")).abs().sort_values(ascending=False)\n",
    "num_stepwise = list(corrs.index[:min(K_STEPWISE, len(corrs))])\n",
    "\n",
    "def kfold_predict_linear(X_df, y_ser, cols, n_splits=5, seed=42):\n",
    "    \"\"\"Fit scaler on EXACT subset 'cols' within each fold; optional row cap for speed.\"\"\"\n",
    "    if len(cols) == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    # Optional global subsample for speed\n",
    "    if (MAX_STEPWISE_ROWS is not None) and (len(X_df) > MAX_STEPWISE_ROWS):\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(len(X_df), size=MAX_STEPWISE_ROWS, replace=False)\n",
    "        X_use = X_df.iloc[idx][cols]\n",
    "        y_use = y_ser.iloc[idx]\n",
    "    else:\n",
    "        X_use = X_df[cols]\n",
    "        y_use = y_ser\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    y_true_list, y_pred_list = [], []\n",
    "    for tr, va in kf.split(X_use):\n",
    "        Xtr, Xva = X_use.iloc[tr], X_use.iloc[va]\n",
    "        ytr, yva = y_use.iloc[tr], y_use.iloc[va]\n",
    "        sc = StandardScaler()\n",
    "        Xtr_s = sc.fit_transform(Xtr)\n",
    "        Xva_s = sc.transform(Xva)\n",
    "        ols = LinearRegression().fit(Xtr_s, ytr)\n",
    "        y_true_list.append(yva.values)\n",
    "        y_pred_list.append(ols.predict(Xva_s))\n",
    "    return cv_summary(y_true_list, y_pred_list)\n",
    "\n",
    "def forward_stepwise(X_df, y_ser, candidates, max_feats=None, tol=1e-4, n_splits=5):\n",
    "    selected, best_score = [], -np.inf\n",
    "    remaining = candidates.copy()\n",
    "    max_feats = max_feats or len(candidates)\n",
    "    while remaining and len(selected) < max_feats:\n",
    "        trial_scores = []\n",
    "        for c in remaining:\n",
    "            cols = selected + [c]\n",
    "            r2m, *_ = kfold_predict_linear(X_df, y_ser, cols, n_splits=n_splits)\n",
    "            trial_scores.append((r2m, c))\n",
    "        trial_scores.sort(reverse=True)\n",
    "        if trial_scores[0][0] > best_score + tol:\n",
    "            best_score, chosen = trial_scores[0]\n",
    "            selected.append(chosen)\n",
    "            remaining.remove(chosen)\n",
    "        else:\n",
    "            break\n",
    "    return selected\n",
    "\n",
    "def backward_stepwise(X_df, y_ser, start_cols, tol=1e-4, n_splits=5):\n",
    "    cols = start_cols.copy()\n",
    "    if len(cols) == 0:\n",
    "        return cols\n",
    "    improved = True\n",
    "    base_r2m, *_ = kfold_predict_linear(X_df, y_ser, cols, n_splits=n_splits)\n",
    "    while improved and len(cols) > 1:\n",
    "        improved = False\n",
    "        trial_scores = []\n",
    "        for c in cols:\n",
    "            trial = [x for x in cols if x != c]\n",
    "            r2m, *_ = kfold_predict_linear(X_df, y_ser, trial, n_splits=n_splits)\n",
    "            trial_scores.append((r2m, c, trial))\n",
    "        trial_scores.sort(reverse=True)\n",
    "        if trial_scores[0][0] > base_r2m + tol:\n",
    "            base_r2m, removed, cols = trial_scores[0][0], trial_scores[0][1], trial_scores[0][2]\n",
    "            improved = True\n",
    "    return cols\n",
    "\n",
    "# Compute stepwise sets\n",
    "fwd_selected = forward_stepwise(X, y, num_stepwise, max_feats=min(12, len(num_stepwise)), n_splits=5)\n",
    "bwd_selected = backward_stepwise(X, y, num_stepwise, n_splits=5)\n",
    "\n",
    "# CV for stepwise models\n",
    "fwd_r2m, fwd_r2s, fwd_rm, fwd_rs = kfold_predict_linear(X, y, fwd_selected, n_splits=5) if fwd_selected else (np.nan, np.nan, np.nan, np.nan)\n",
    "bwd_r2m, bwd_r2s, bwd_rm, bwd_rs = kfold_predict_linear(X, y, bwd_selected, n_splits=5) if bwd_selected else (np.nan, np.nan, np.nan, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d45e4089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCR: PCA(numeric) + OHE(cats) + OLS (inner CV for n_components)\n",
    "num_pcr = Pipeline([(\"scale\", StandardScaler()), (\"pca\", PCA())])\n",
    "\n",
    "trans = [(\"num\", num_pcr, num_cols_all)]\n",
    "if len(cat_cols):\n",
    "    trans.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols))\n",
    "\n",
    "pre_pcr = ColumnTransformer(transformers=trans, remainder=\"drop\")\n",
    "to_dense = FunctionTransformer(densify)\n",
    "pcr_pipe = Pipeline([(\"pre\", pre_pcr), (\"to_dense\", to_dense), (\"reg\", LinearRegression())])\n",
    "\n",
    "max_pca = max(1, min(25, len(num_cols_all)))\n",
    "pcr_param = {\"pre__num__pca__n_components\": list(range(1, max_pca + 1))}\n",
    "\n",
    "# inner-CV row cap for speed\n",
    "MAX_INNER_ROWS = 120_000\n",
    "\n",
    "def nested_cv_pipe(pipe, param_grid, X_df, y_ser, n_splits=5, seed=42):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    y_true_list, y_pred_list, best_params = [], [], []\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for tr, va in kf.split(X_df):\n",
    "        Xtr, Xva = X_df.iloc[tr], X_df.iloc[va]\n",
    "        ytr, yva = y_ser.iloc[tr], y_ser.iloc[va]\n",
    "\n",
    "        # cap rows during inner CV\n",
    "        if (MAX_INNER_ROWS is not None) and (len(Xtr) > MAX_INNER_ROWS):\n",
    "            idx = rng.choice(len(Xtr), size=MAX_INNER_ROWS, replace=False)\n",
    "            Xcv, ycv = Xtr.iloc[idx], ytr.iloc[idx]\n",
    "        else:\n",
    "            Xcv, ycv = Xtr, ytr\n",
    "\n",
    "        try:\n",
    "            gs = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "        except TypeError:\n",
    "            gs = GridSearchCV(pipe, param_grid, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "        gs.fit(Xcv, ycv)\n",
    "\n",
    "        best = gs.best_estimator_\n",
    "        y_true_list.append(yva.values)\n",
    "        y_pred_list.append(best.predict(Xva))\n",
    "        best_params.append(gs.best_params_)\n",
    "    r2m, r2s, rm, rs = cv_summary(y_true_list, y_pred_list)\n",
    "    return r2m, r2s, rm, rs, best_params\n",
    "\n",
    "pcr_r2m, pcr_r2s, pcr_rm, pcr_rs, pcr_params = nested_cv_pipe(pcr_pipe, pcr_param, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08239223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLSR: StandardScaler+OHE -> PLSRegression (inner CV for n_components)\n",
    "trans_pls = [(\"num\", StandardScaler(), num_cols_all)]\n",
    "if len(cat_cols):\n",
    "    trans_pls.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols))\n",
    "\n",
    "pre_pls = ColumnTransformer(transformers=trans_pls, remainder=\"drop\")\n",
    "pls_pipe = Pipeline([(\"pre\", pre_pls), (\"to_dense\", to_dense), (\"reg\", PLSRegression(scale=False))])\n",
    "\n",
    "max_pls = max(1, min(15, len(num_cols_all)))\n",
    "pls_param = {\"reg__n_components\": list(range(1, max_pls + 1))}\n",
    "\n",
    "pls_r2m, pls_r2s, pls_rm, pls_rs, pls_params = nested_cv_pipe(pls_pipe, pls_param, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67d88095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 3 — 5-fold CV (mean ± std) ===\n",
      "                          Model CV R^2 (mean ± std) CV RMSE (mean ± std)\n",
      "   Forward Stepwise (on 12 num)     0.1362 ± 0.0053      6.1641 ± 0.0563\n",
      "  Backward Stepwise (on 20 num)     0.1379 ± 0.0051      6.1581 ± 0.0554\n",
      " PCR (best n_components via CV)     0.1392 ± 0.0028      6.1311 ± 0.0484\n",
      "PLSR (best n_components via CV)     0.1392 ± 0.0028      6.1311 ± 0.0483\n"
     ]
    }
   ],
   "source": [
    "# Summaries (5-fold CV)\n",
    "cv_rows = []\n",
    "print_cv_row(cv_rows, f\"Forward Stepwise (on {len(fwd_selected)} num)\", fwd_r2m, fwd_r2s, fwd_rm, fwd_rs)\n",
    "print_cv_row(cv_rows, f\"Backward Stepwise (on {len(bwd_selected)} num)\", bwd_r2m, bwd_r2s, bwd_rm, bwd_rs)\n",
    "print_cv_row(cv_rows, \"PCR (best n_components via CV)\", pcr_r2m, pcr_r2s, pcr_rm, pcr_rs)\n",
    "print_cv_row(cv_rows, \"PLSR (best n_components via CV)\", pls_r2m, pls_r2s, pls_rm, pls_rs)\n",
    "\n",
    "cv_table = pd.DataFrame(cv_rows)\n",
    "print(\"\\n=== Week 3 — 5-fold CV (mean ± std) ===\")\n",
    "print(cv_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dc844ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Week 3 — Common Holdout (30%) ===\n",
      "            Model  Test R^2  Test RMSE                                                                                                                                                                                                                                                                            Params\n",
      " Forward Stepwise  0.136078   6.116439                                                                                                                    {'features': ['genhlth', 'diabetes_012', 'highbp', 'age', 'diffwalk', 'physactivity', 'fruits', 'stroke', 'hvyalcoholconsump', 'physhlth', 'sex', 'highchol']}\n",
      "Backward Stepwise  0.137271   6.112218 {'features': ['genhlth', 'diabetes_012', 'highbp', 'diffwalk', 'physactivity', 'physhlth', 'highchol', 'education', 'income', 'fruits', 'menthlth', 'veggies', 'nodocbccost', 'heartdiseaseorattack', 'hvyalcoholconsump', 'sex', 'age', 'cholcheck', 'stroke', 'anyhealthcare']}\n",
      "              PCR  0.138152   6.109093                                                                                                                                                                                                                                                              {'n_components': 21}\n",
      "             PLSR  0.138152   6.109094                                                                                                                                                                                                                                                               {'n_components': 8}\n"
     ]
    }
   ],
   "source": [
    "# Common 30% holdout for apples-to-apples comparison \n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Forward holdout\n",
    "if fwd_selected:\n",
    "    sc_f = StandardScaler().fit(X_tr[fwd_selected])\n",
    "    Xtr_f = sc_f.transform(X_tr[fwd_selected])\n",
    "    Xte_f = sc_f.transform(X_te[fwd_selected])\n",
    "    ols_f = LinearRegression().fit(Xtr_f, y_tr)\n",
    "    fwd_test = {\"Model\":\"Forward Stepwise\",\n",
    "                \"Test R^2\": r2_score(y_te, ols_f.predict(Xte_f)),\n",
    "                \"Test RMSE\": rmse(y_te, ols_f.predict(Xte_f)),\n",
    "                \"Params\": {\"features\": fwd_selected}}\n",
    "else:\n",
    "    fwd_test = {\"Model\":\"Forward Stepwise\",\"Test R^2\":np.nan,\"Test RMSE\":np.nan,\"Params\":{\"features\":[]}}\n",
    "\n",
    "# Backward holdout\n",
    "if bwd_selected:\n",
    "    sc_b = StandardScaler().fit(X_tr[bwd_selected])\n",
    "    Xtr_b = sc_b.transform(X_tr[bwd_selected])\n",
    "    Xte_b = sc_b.transform(X_te[bwd_selected])\n",
    "    ols_b = LinearRegression().fit(Xtr_b, y_tr)\n",
    "    bwd_test = {\"Model\":\"Backward Stepwise\",\n",
    "                \"Test R^2\": r2_score(y_te, ols_b.predict(Xte_b)),\n",
    "                \"Test RMSE\": rmse(y_te, ols_b.predict(Xte_b)),\n",
    "                \"Params\": {\"features\": bwd_selected}}\n",
    "else:\n",
    "    bwd_test = {\"Model\":\"Backward Stepwise\",\"Test R^2\":np.nan,\"Test RMSE\":np.nan,\"Params\":{\"features\":[]}}\n",
    "\n",
    "# PCR holdout (refit with best n_components on train)\n",
    "try:\n",
    "    gs_pcr = GridSearchCV(pcr_pipe, pcr_param, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "except TypeError:\n",
    "    gs_pcr = GridSearchCV(pcr_pipe, pcr_param, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "gs_pcr.fit(X_tr, y_tr)\n",
    "pcr_best = gs_pcr.best_estimator_\n",
    "pcr_n = pcr_best.get_params().get(\"pre__num__pca__n_components\")\n",
    "pcr_pred = np.ravel(pcr_best.predict(X_te))\n",
    "pcr_test = {\"Model\":\"PCR\", \"Params\":{\"n_components\": int(pcr_n) if pcr_n is not None else None},\n",
    "            \"Test R^2\": r2_score(y_te, pcr_pred), \"Test RMSE\": rmse(y_te, pcr_pred)}\n",
    "\n",
    "# PLSR holdout\n",
    "try:\n",
    "    gs_pls = GridSearchCV(pls_pipe, pls_param, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "except TypeError:\n",
    "    gs_pls = GridSearchCV(pls_pipe, pls_param, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "gs_pls.fit(X_tr, y_tr)\n",
    "pls_best = gs_pls.best_estimator_\n",
    "pls_n = int(pls_best.get_params().get(\"reg__n_components\"))\n",
    "pls_pred = np.ravel(pls_best.predict(X_te))\n",
    "pls_test = {\"Model\":\"PLSR\", \"Params\":{\"n_components\": pls_n},\n",
    "            \"Test R^2\": r2_score(y_te, pls_pred), \"Test RMSE\": rmse(y_te, pls_pred)}\n",
    "\n",
    "hold_table = pd.DataFrame([fwd_test, bwd_test, pcr_test, pls_test])\n",
    "print(\"\\n=== Week 3 — Common Holdout (30%) ===\")\n",
    "print(hold_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e58df",
   "metadata": {},
   "source": [
    "Week 3 — Breakdown (Diabetes BRFSS2015)\n",
    "1) Goal (what we’re evaluating)\n",
    "\n",
    "Greedy subset models: Forward & Backward stepwise linear regression (interpretable, but can be unstable).\n",
    "\n",
    "Dimension-reduction models: PCR (PCA → OLS) and PLSR (PLSRegression).\n",
    "\n",
    "Validation: Report 5-fold CV mean ± std of R² and RMSE, plus a shared 30% holdout (apples-to-apples).\n",
    "\n",
    "2) Data & target (how the target is chosen)\n",
    "\n",
    "Loads diabetes_012_health_indicators_BRFSS2015\n",
    "\n",
    "Picks a continuous target; default preference is bmi.\n",
    "Tip: lock it with\n",
    "\n",
    "target_col = \"bmi\"\n",
    "\n",
    "\n",
    "Drops rows with missing target; keeps the rest.\n",
    "\n",
    "3) Features & basic preprocessing\n",
    "\n",
    "Splits into:\n",
    "\n",
    "Numeric columns (most of BRFSS) → num_cols_all\n",
    "\n",
    "Categorical columns (if any) → cat_cols\n",
    "\n",
    "Quick NA handling: numerics → 0.0, categoricals → \"__missing__\".\n",
    "\n",
    "Standardization (StandardScaler) is applied inside each CV fold (prevents leakage).\n",
    "\n",
    "4) Stepwise selection (interpretability-first)\n",
    "\n",
    "We rank numeric features by absolute correlation with the target, keep top-K as candidates.\n",
    "\n",
    "Code knob: K_STEPWISE = 20\n",
    "\n",
    "For speed on large N, can subsample rows during stepwise CV:\n",
    "\n",
    "Code knob: MAX_STEPWISE_ROWS = 120_000 (set to None to use all rows)\n",
    "\n",
    "Forward stepwise:\n",
    "\n",
    "Start empty → add the feature that gives the largest CV R² gain; stop when gain < tol.\n",
    "\n",
    "Backward stepwise:\n",
    "\n",
    "Start with all top-K; remove the feature whose removal improves CV R² the most; stop when no improvement.\n",
    "\n",
    "Both use linear regression on standardized features (only the current subset).\n",
    "\n",
    "Outputs:\n",
    "\n",
    "fwd_selected, bwd_selected (lists of chosen numeric features)\n",
    "\n",
    "\n",
    "When to use: you need original-feature interpretability and a compact subset.\n",
    "\n",
    "5) PCR (Principal Components Regression)\n",
    "\n",
    "Pipeline: scale numeric → PCA(n_components) → concatenate OHE(cats) → OLS.\n",
    "\n",
    "\n",
    "Motivation: orthogonalizes correlated predictors (handles multicollinearity), but components are variance-oriented (not target-oriented).\n",
    "\n",
    "Outputs:\n",
    "\n",
    "Best n_components per fold in pcr_params (dicts)\n",
    "\n",
    "6) PLSR (Partial Least Squares Regression)\n",
    "\n",
    "Pipeline: scale+OHE → PLSRegression(n_components).\n",
    "\n",
    "\n",
    "Motivation: Finds directions that maximize covariance with y (often needs fewer components than PCR).\n",
    "\n",
    "\n",
    "7) Nested CV & metrics (how scores are computed)\n",
    "\n",
    "Outer 5-fold CV: unbiased performance estimate.\n",
    "\n",
    "Inside each outer train fold, GridSearchCV tunes components (PCR/PLSR).\n",
    "\n",
    "\n",
    "RMSE in same units as the target (here, BMI units).\n",
    "\n",
    "8) Common 30% holdout (final apples-to-apples test)\n",
    "\n",
    "We refit each approach on the same 70% train and score on the same 30% test:\n",
    "\n",
    "Forward / Backward: scale using train subset, fit OLS, score on test.\n",
    "\n",
    "PCR / PLSR: re-run grid search on the train to pick the best n_components, then score on test.\n",
    "\n",
    "Results printed in hold_table with tuned params.\n",
    "\n",
    "9) How to read the outputs\n",
    "\n",
    "cv_table (mean ± std across folds): Compare models by higher CV R² and lower CV RMSE. \n",
    "\n",
    "hold_table:\n",
    "Confirms with an independent test R²/RMSE. Minor deviations from CV are normal.\n",
    "\n",
    "\n",
    "Runtime too slow:\n",
    "\n",
    "Lower K_STEPWISE, MAX_STEPWISE_ROWS, MAX_INNER_ROWS\n",
    "\n",
    "Use n_splits=3 temporarily.\n",
    "\n",
    "Overfitting signs: strong train fit, weak CV → prefer PLSR or PCR (fewer components), or try Week 2 regularization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
